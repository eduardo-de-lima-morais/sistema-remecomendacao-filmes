{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.0 Introdução**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/ibtesama/getting-started-with-a-movie-recommendation-system/notebook\n",
    "#https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset?resource=download\n",
    "#https://www.kaggle.com/code/saritrath/movierecommendersystems\n",
    "#https://www.kaggle.com/code/faiqueali/tensorflow-movie-recommender-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Pacotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install spacy\n",
    "# !python -m spacy download en_core_web_lg \n",
    "# %pip install sentence-transformers\n",
    "# %pip install transformers[sentence]\n",
    "# %pip install nltk\n",
    "# %pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trat. dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "#windows\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "#ml\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split as train_test_split_skl\n",
    "\n",
    "#lib recomendacao \n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "#ignorar avisos\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#nlp\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.0 Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Extração**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets download -d rounakbanik/the-movies-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['credits.csv', 'filmes_final.csv', 'keywords.csv', 'links.csv', 'links_small.csv', 'movies_metadata.csv', 'ratings.csv', 'ratings_small.csv']\n"
     ]
    }
   ],
   "source": [
    "#Caminho para o arquivo zip baixado\n",
    "zip_file_path = 'the-movies-dataset.zip'\n",
    "\n",
    "#Caminho para a pasta onde os arquivos serão extraídos\n",
    "extracted_folder_path = 'bases'\n",
    "\n",
    "#Extrair os arquivos do zip\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)\n",
    "\n",
    "#Listar os arquivos extraídos\n",
    "extracted_files = os.listdir(extracted_folder_path)\n",
    "print(extracted_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Carregamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv('C:/Users/eduar/OneDrive/Área de Trabalho/Python/recomendador/bases/credits.csv')\n",
    "keywords = pd.read_csv('C:/Users/eduar/OneDrive/Área de Trabalho/Python/recomendador/bases/keywords.csv')\n",
    "\n",
    "#dados de filmes\n",
    "movies_metadata = ['original_language','genres','id', 'original_title','overview','popularity',\n",
    "'production_companies','production_countries','runtime','tagline','title','vote_average','vote_count']\n",
    "movies_metadata = pd.read_csv('C:/Users/eduar/OneDrive/Área de Trabalho/Python/recomendador/bases/movies_metadata.csv',\n",
    "usecols=movies_metadata).drop([19730, 29503, 35587])#.iloc[:100]\n",
    "\n",
    "#avaliacoes\n",
    "ratings = pd.read_csv('C:/Users/eduar/OneDrive/Área de Trabalho/Python/recomendador/bases/ratings.csv')\n",
    "ratings = ratings.drop(['timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Tratamento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.1 Dados filmes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_metadata = movies_metadata[movies_metadata['original_language']=='en']\n",
    "# movies_metadata['id'] = movies_metadata['id'].astype('int64')\n",
    "# content_df = pd.merge(movies_metadata, credits, left_on='id', right_on='id', how='left').dropna(subset=['id'])\n",
    "# content_df = pd.merge(content_df, keywords, left_on='id', right_on='id', how='left').dropna(subset=['id'])\n",
    "# content_df['genres']= content_df['genres'].fillna('[]').apply(literal_eval).apply(lambda x:[i['name'] for i in x] if isinstance(x,list) else [])\n",
    "# content_df['production_companies']= content_df['production_companies'].fillna('[]').apply(literal_eval).apply(lambda x:[i['name'] for i in x] if isinstance(x,list) else [])\n",
    "# content_df['production_countries']= content_df['production_countries'].fillna('[]').apply(literal_eval).apply(lambda x:[i['name'] for i in x] if isinstance(x,list) else [])\n",
    "# content_df['keywords']= content_df['keywords'].fillna('[]').apply(literal_eval).apply(lambda x:[i['name'] for i in x] if isinstance(x,list) else [])\n",
    "# content_df['cast']= content_df['cast'].fillna('[]').apply(literal_eval).apply(lambda x:[i['name'] for i in x] if isinstance(x,list) else [])\n",
    "# content_df['crew'] = content_df['crew'].apply(lambda x: eval(x) if pd.notnull(x) and x != '[]' else [])\n",
    "# content_df['director'] = content_df['crew'].apply(lambda x: next((i['name'] for i in x if i['job'] == 'Director'), np.nan))\n",
    "# text = ['original_title', 'genres', 'overview','production_companies', 'tagline', 'keywords', 'director', 'cast']\n",
    "# content_df['bag_of_words'] = content_df[text[0:]].astype(str).apply(lambda x: ' '.join(x), axis=1)\n",
    "# content_df['bag_of_words'] = content_df['bag_of_words'].apply(lambda texto: ' '.join([token.lemma_ for token in nlp(texto) if token.pos_ == 'NOUN']))\n",
    "# content_df = content_df.dropna(subset=['bag_of_words'])\n",
    "# content_df['bag_of_words'] = content_df['bag_of_words'].astype(str)\n",
    "# content_df = content_df[content_df['original_language']=='en']\n",
    "# content_df = content_df[content_df['vote_average']>=3.5]\n",
    "# content_df = content_df[content_df['vote_count']>=50]\n",
    "\n",
    "# #salvar\n",
    "# content_df.to_csv('bases/filmes_final.csv', index=False,mode='w')\n",
    "content_df = pd.read_csv('bases/filmes_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Avaliações**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df para filtragem de conteudo\n",
    "avaliacoes_total = pd.merge(ratings, content_df, left_on='movieId', right_on='id', how='inner').dropna(subset=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.0 Filtragem de Conteúdo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processamento\n",
    "avaliacoes = avaliacoes_total[avaliacoes_total['rating']>3]\n",
    "\n",
    "#Carregue o modelo BERT pré-treinado\n",
    "bert_model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "#Representação em embeddings do texto\n",
    "texto_embeddings = bert_model.encode(content_df['bag_of_words'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "#df\n",
    "embedding_df = pd.DataFrame(texto_embeddings.numpy())\n",
    "\n",
    "#Calcular a similaridade de cosseno entre os filmes usando os embeddings do BERT\n",
    "cosine_similarities_bert = cosine_similarity(embedding_df, embedding_df)\n",
    "\n",
    "#Criar um DataFrame de similaridades\n",
    "similaridades_df_bert = pd.DataFrame(cosine_similarities_bert, index=content_df['original_title'], columns=content_df['original_title'])\n",
    "\n",
    "#Função para obter recomendações para um usuário específico usando embeddings do BERT\n",
    "def obter_recomendacoes_bert(usuario_id):\n",
    "    #Filtrar avaliações do usuário\n",
    "    avaliacoes_usuario = avaliacoes[avaliacoes['userId'] == usuario_id]\n",
    "\n",
    "    #Filtrar filmes que o usuário ainda não avaliou\n",
    "    filmes_nao_avaliados = content_df[~content_df['original_title'].isin(avaliacoes_usuario['original_title'])]\n",
    "\n",
    "    #Calcular a pontuação ponderada para cada filme não avaliado usando embeddings do BERT\n",
    "    filmes_nao_avaliados['pontuacao'] = filmes_nao_avaliados.apply(lambda row: similaridades_df_bert.loc[row['original_title'], \n",
    "    avaliacoes_usuario['original_title']].sum(),axis=1)   \n",
    "    filmes_nao_avaliados['pontuacao'] = pd.to_numeric(filmes_nao_avaliados['pontuacao'], errors='coerce')\n",
    "\n",
    "    #Ordenar filmes por pontuação em ordem decrescente\n",
    "    recomendacoes = filmes_nao_avaliados.sort_values(by='pontuacao', ascending=False)\n",
    "\n",
    "    return recomendacoes,avaliacoes_usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>runtime</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>keywords</th>\n",
       "      <th>director</th>\n",
       "      <th>bag_of_words</th>\n",
       "      <th>pontuacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>['Drama', 'Action', 'Thriller', 'Crime']</td>\n",
       "      <td>13641</td>\n",
       "      <td>en</td>\n",
       "      <td>The Air I Breathe</td>\n",
       "      <td>A drama based on an ancient Chinese proverb th...</td>\n",
       "      <td>8.876157</td>\n",
       "      <td>['NALA Films']</td>\n",
       "      <td>['Mexico', 'United States of America']</td>\n",
       "      <td>95.0</td>\n",
       "      <td>The question is not whether we will die, but h...</td>\n",
       "      <td>The Air I Breathe</td>\n",
       "      <td>6.1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>['Brendan Fraser', 'Andy García', 'Kevin Bacon...</td>\n",
       "      <td>[{'credit_id': '52fe45869251416c75059867', 'de...</td>\n",
       "      <td>['corruption', 'horse race', 'suicide attempt'...</td>\n",
       "      <td>Jieho Lee</td>\n",
       "      <td>drama action thriller crime ' drama proverb li...</td>\n",
       "      <td>23.319563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>['Action', 'Crime', 'Comedy']</td>\n",
       "      <td>40805</td>\n",
       "      <td>en</td>\n",
       "      <td>The Green Hornet</td>\n",
       "      <td>Britt Reid (Seth Rogen), the heir to the large...</td>\n",
       "      <td>7.888013</td>\n",
       "      <td>['Original Film', 'Sony Pictures Entertainment...</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>119.0</td>\n",
       "      <td>Breaking the Law to Protect It.</td>\n",
       "      <td>The Green Hornet</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>['Seth Rogen', 'Jay Chou', 'Christoph Waltz', ...</td>\n",
       "      <td>[{'credit_id': '52fe45a4c3a36847f80d25a9', 'de...</td>\n",
       "      <td>['bomb', 'martial arts', 'assassin', 'vandalis...</td>\n",
       "      <td>Michel Gondry</td>\n",
       "      <td>crime comedy ' heir newspaper fortune playboy ...</td>\n",
       "      <td>22.214787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>['Romance', 'Comedy', 'Drama']</td>\n",
       "      <td>10247</td>\n",
       "      <td>en</td>\n",
       "      <td>He Was a Quiet Man</td>\n",
       "      <td>A troubled loner, Bob Maconel, imagines blowin...</td>\n",
       "      <td>4.176044</td>\n",
       "      <td>['Neo Art &amp; Logic', 'Quiet Man Productions']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>95.0</td>\n",
       "      <td>He seemed like such a nice guy.. He pretty muc...</td>\n",
       "      <td>He Was a Quiet Man</td>\n",
       "      <td>6.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>['Christian Slater', 'John Gulager', 'Elisha C...</td>\n",
       "      <td>[{'credit_id': '52fe43499251416c7500a8a3', 'de...</td>\n",
       "      <td>['suicide', 'paraplegic', 'office', 'aquarium'...</td>\n",
       "      <td>Frank A. Cappello</td>\n",
       "      <td>romance comedy drama loner tower revolver offi...</td>\n",
       "      <td>22.071098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        genres     id original_language  \\\n",
       "4078  ['Drama', 'Action', 'Thriller', 'Crime']  13641                en   \n",
       "4874             ['Action', 'Crime', 'Comedy']  40805                en   \n",
       "4059            ['Romance', 'Comedy', 'Drama']  10247                en   \n",
       "\n",
       "          original_title                                           overview  \\\n",
       "4078   The Air I Breathe  A drama based on an ancient Chinese proverb th...   \n",
       "4874    The Green Hornet  Britt Reid (Seth Rogen), the heir to the large...   \n",
       "4059  He Was a Quiet Man  A troubled loner, Bob Maconel, imagines blowin...   \n",
       "\n",
       "      popularity                               production_companies  \\\n",
       "4078    8.876157                                     ['NALA Films']   \n",
       "4874    7.888013  ['Original Film', 'Sony Pictures Entertainment...   \n",
       "4059    4.176044       ['Neo Art & Logic', 'Quiet Man Productions']   \n",
       "\n",
       "                        production_countries  runtime  \\\n",
       "4078  ['Mexico', 'United States of America']     95.0   \n",
       "4874            ['United States of America']    119.0   \n",
       "4059            ['United States of America']     95.0   \n",
       "\n",
       "                                                tagline               title  \\\n",
       "4078  The question is not whether we will die, but h...   The Air I Breathe   \n",
       "4874                    Breaking the Law to Protect It.    The Green Hornet   \n",
       "4059  He seemed like such a nice guy.. He pretty muc...  He Was a Quiet Man   \n",
       "\n",
       "      vote_average  vote_count  \\\n",
       "4078           6.1       115.0   \n",
       "4874           5.5      1274.0   \n",
       "4059           6.5        83.0   \n",
       "\n",
       "                                                   cast  \\\n",
       "4078  ['Brendan Fraser', 'Andy García', 'Kevin Bacon...   \n",
       "4874  ['Seth Rogen', 'Jay Chou', 'Christoph Waltz', ...   \n",
       "4059  ['Christian Slater', 'John Gulager', 'Elisha C...   \n",
       "\n",
       "                                                   crew  \\\n",
       "4078  [{'credit_id': '52fe45869251416c75059867', 'de...   \n",
       "4874  [{'credit_id': '52fe45a4c3a36847f80d25a9', 'de...   \n",
       "4059  [{'credit_id': '52fe43499251416c7500a8a3', 'de...   \n",
       "\n",
       "                                               keywords           director  \\\n",
       "4078  ['corruption', 'horse race', 'suicide attempt'...          Jieho Lee   \n",
       "4874  ['bomb', 'martial arts', 'assassin', 'vandalis...      Michel Gondry   \n",
       "4059  ['suicide', 'paraplegic', 'office', 'aquarium'...  Frank A. Cappello   \n",
       "\n",
       "                                           bag_of_words  pontuacao  \n",
       "4078  drama action thriller crime ' drama proverb li...  23.319563  \n",
       "4874  crime comedy ' heir newspaper fortune playboy ...  22.214787  \n",
       "4059  romance comedy drama loner tower revolver offi...  22.071098  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exemplo de recomendações para o usuário com ID 1 usando embeddings do BERT\n",
    "recomendacoes,avaliacoes_usuario = obter_recomendacoes_bert(270872)\n",
    "recomendacoes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8659\n",
      "107720\n",
      "179792\n",
      "45811\n",
      "229879\n",
      "243443\n",
      "0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Validacao de desempenho do modelo\n",
    "#listar usuarios\n",
    "user_counts = avaliacoes_total['userId'].value_counts()\n",
    "user_list = user_counts[user_counts > 800].index.tolist()\n",
    "#user_list = [107720]\n",
    "#criar df vazio\n",
    "recomendacoes_total = pd.DataFrame(columns=['userId', 'original_title', 'rating'])\n",
    "filmes = avaliacoes_total[['userId','original_title','rating']]\n",
    "\n",
    "for user in user_list:\n",
    "    try:\n",
    "      usuario_id = user\n",
    "      #todas as avaliacoes do usuario\n",
    "      avaliacoes_usuario = filmes[filmes['userId'] == user]\n",
    "      #Agora é necessario dividir entre treino e teste\n",
    "      train, test = train_test_split_skl(avaliacoes_usuario, test_size=0.3, random_state=42)\n",
    "      #no treino, deixaremos apenas avaliacoes positivas\n",
    "      train = train[train['rating']>4]\n",
    "      #balancear test\n",
    "      test_5 = test[test['rating']>=4]\n",
    "      test_3 = test[test['rating']<3]\n",
    "      count_3 = len(test_3)\n",
    "      count_5 = len(test_5)\n",
    "      diferenca = count_5 - count_3\n",
    "      if diferenca > 0:\n",
    "        test = test_5.head(count_3).append(test_3)\n",
    "        limit = len(test.head(5))\n",
    "      else:\n",
    "        test = test_3.head(count_5).append(test_5)\n",
    "        limit = len(test.head(5))\n",
    "\n",
    "      #Calcular a pontuação ponderada para cada filme não avaliado usando embeddings do BERT  \n",
    "      test['pontuacao'] = test.apply(lambda row: similaridades_df_bert.loc[row['original_title'],train['original_title']].sum(),axis=1)\n",
    "      test['pontuacao'] = pd.to_numeric(test['pontuacao'], errors='coerce')\n",
    "      #Ordenar filmes por pontuação em ordem decrescente\n",
    "      recomendacoes = test.sort_values(by='pontuacao', ascending=False).head(limit)\n",
    "      recomendacoes = recomendacoes[['userId','original_title','rating']]\n",
    "      recomendacoes_total = pd.concat([recomendacoes, recomendacoes_total])\n",
    "      print(user)\n",
    "    except:\n",
    "      print(\"Erro: \"+user)\n",
    "      pass\n",
    "\n",
    "recomendacoes_total['bem_avaliado'] = recomendacoes_total['rating'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "recall = recomendacoes_total['bem_avaliado'].mean()\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.0 Filtragem Colaborativa**\n",
    "\n",
    "- Surprise\n",
    "- O que usuários parecidos estão assistindo\n",
    "- Basicamente precisa apenas de user item e rating para rodar esse modelo. simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8570\n",
      "MAE:  0.6575\n",
      "rmse: 0.857011571331061\n",
      "mae: 0.857011571331061\n",
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8551  0.8549  0.8572  0.8568  0.8559  0.8560  0.0009  \n",
      "MAE (testset)     0.6563  0.6557  0.6576  0.6573  0.6565  0.6567  0.0007  \n",
      "Fit time          92.99   88.00   86.15   85.40   86.94   87.90   2.69    \n",
      "Test time         25.98   27.13   18.49   13.65   16.86   20.42   5.25    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>estimated_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>Letters from Iwo Jima</td>\n",
       "      <td>4.651386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>On Her Majesty's Secret Service</td>\n",
       "      <td>4.599228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>Kindergarten Cop</td>\n",
       "      <td>4.562276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>Mr. Smith Goes to Washington</td>\n",
       "      <td>4.555736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>Mission: Impossible II</td>\n",
       "      <td>4.464182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       original_title  estimated_rating\n",
       "827             Letters from Iwo Jima          4.651386\n",
       "1005  On Her Majesty's Secret Service          4.599228\n",
       "779                  Kindergarten Cop          4.562276\n",
       "950      Mr. Smith Goes to Washington          4.555736\n",
       "927            Mission: Impossible II          4.464182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df para filtragem de colaborativa\n",
    "df = pd.merge(ratings, content_df, left_on='movieId', right_on='id', how='inner').dropna(subset=['id'])\n",
    "df = (df[['userId', 'original_title','rating']])\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "avaliacoes = Dataset.load_from_df(df[['userId', 'original_title', 'rating']], reader)\n",
    "\n",
    "#modelo\n",
    "train, test = train_test_split(avaliacoes, test_size=0.2)\n",
    "model = SVD()\n",
    "model.fit(train)\n",
    "predictions = model.test(test)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)\n",
    "print(f'rmse: {rmse}')\n",
    "print(f'mae: {rmse}')\n",
    "results = cross_validate(model, avaliacoes, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "#recomendacoes\n",
    "user_id = 270872\n",
    "unique_ids = df['original_title'].unique()\n",
    "items_rated_by_user = df[df['userId'] == user_id]['userId'].unique()\n",
    "items_to_predict = np.setdiff1d(unique_ids, items_rated_by_user)\n",
    "predictions_list = [(item, model.predict(user_id, item).est) for item in items_to_predict]\n",
    "predictions_df = pd.DataFrame(predictions_list, columns=['original_title', 'estimated_rating']).sort_values('estimated_rating', ascending=False)\n",
    "display(predictions_df.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
